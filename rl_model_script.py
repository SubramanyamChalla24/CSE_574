# -*- coding: utf-8 -*-
"""planning_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10jz1emrtwIWe0uw2OlMYU_A82mD2H2Su
"""

!pip install openai

!pip install stable_baselines3

!pip install transformers

!pip install huggingface_hub

"""Prompt generation using LLM"""

from transformers import AutoModelForCausalLM, AutoTokenizer
import huggingface_hub


def generate_prompt_transformer(action):

    tokenizer = AutoTokenizer.from_pretrained('gpt2')
    model = AutoModelForCausalLM.from_pretrained('gpt2')

    input_ids = tokenizer(action, return_tensors="pt")["input_ids"]
    attention_mask = tokenizer(action, return_tensors="pt")["attention_mask"]

    generated_ids = model.generate(
        input_ids=input_ids,
        attention_mask=attention_mask,
        max_length=100,
        num_beams=5,
        repetition_penalty=2.0,
        length_penalty=1.0,
        early_stopping=True,
    )

    # Decode the generated text
    prompt = tokenizer.decode(generated_ids[0], skip_special_tokens=True)
    return prompt


text = generate_prompt_transformer("emotionality, scarcity commercial for exclusive bags")
print(text)

"""Manual prompt generation based on persuasion strategies and product specifics"""

import openai
openai.api_key = "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"

def generate_image_prompt_without_llm(persuasion_strategy, product_specifics):

  prompt = f"Generate an image without text for a {product_specifics['product_name']} commercial using the {persuasion_strategy} persuasion strategy. The image should highlight the following key features and benefits of the product:\n"
  for feature in product_specifics['features']:
    prompt += f"* {feature}\n"

  return prompt

product_specifics = {
    "product_name": "iPhone 14",
    "features": ["new camera system", "faster processor", "longer battery life"],
}

persuasion_strategy = "emotional"

prompt = generate_image_prompt_without_llm(persuasion_strategy, product_specifics)

print(prompt)

"""Image generation from prompt"""

!pip install openai
!pip install diffusers
!pip install transformers
!pip install accelerate

!pip -qqq install bitsandbytes accelerate

import openai
import time
import requests
import os
import torch
from diffusers import StableDiffusionXLPipeline
from PIL import Image

pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16
)
pipe = pipe.to("cuda")
num_images = 5
# Function to generate images based on a prompt
def prompt_to_image(prompt, directory="images"):

    for i in range(num_images):

        image = pipe(prompt).images[0]

        obj_directory = os.path.join(directory)
        if not os.path.exists(obj_directory):
            os.makedirs(obj_directory)

        image.save(f"{obj_directory}/{prompt[25:].replace(' ', '_')}_{i}.png", format="PNG")
        print(f"Image {i} for prompt '{prompt}' successfully saved.")

prompt_to_image(prompt)

"""feedback loop"""

import statistics

def get_human_feedback():
  scores = []
  for i in range(0,num_images):
     scores.append((int)(input("Enter your feedback on a scale of 1-10 for image{}.png ".format(i))))
  average = statistics.mean(scores)
  if average > 5:
    return 5
  else :
    return -2

import base64

# Define a function for getting AI feedback on images
def get_ai_feedback(image_path):
    try:
        with open(image_path, 'rb') as image_file:
            image_content = base64.b64encode(image_file.read()).decode('utf-8')
            response = openai.Image.create(files=[{"data": {"base64": image_content}}], model="clip-vit-base-patch16")
            feedback = response.output.text
            return int(feedback)
    except Exception as e:
        print(f"Error: {e}")
        return None

# Example usage
image_path = '/content/image0.png'  # Provide the path to your image file
ai_feedback = get_ai_feedback(image_path)
if ai_feedback is not None:
    print(f"AI feedback for the image is: {ai_feedback}")

def get_ai_feedback_rating_for_image_link(image_link):

  feedback = openai.Feedback.create(
      feedback_options={"ai": True},
      file=image_link
  )

  return feedback["ratings"]["ai"]

"""RL model training for selecting persuasive strategies (still working on it)"""

import gym
import stable_baselines3
import requests


class AdsEnv(gym.Env):
    def __init__(self, persuasion_strategies):
        self.persuasion_strategies = persuasion_strategies
        self.state_space = gym.spaces.Discrete(len(self.persuasion_strategies) ** 3)
        self.action_space = gym.spaces.Discrete(len(self.persuasion_strategies))
        self.state = None
        self.image = None
        self.observation_space = self.state_space
        self.selected_persuasion_strategies = set()


    def reset(self):
      self.state = 0
      self.image = None
      self.selected_persuasion_strategies.clear()
      return self.state

    def step(self, action):

        persuasion_strategy_indices = [action % (len(self.persuasion_strategies))]
        persuasion_strategies = [self.persuasion_strategies[i] for i in persuasion_strategy_indices]

        if len(self.selected_persuasion_strategies) != len(persuasion_strategies):
            reward = -2
        else:
            reward = 2

        for persuasion_strategy in persuasion_strategies:
          self.selected_persuasion_strategies.add(persuasion_strategy)

        print("persuasion strategy selected is:{}".format(persuasion_strategies))

        prompt = generate_image_prompt_without_llm(persuasion_strategies[0], product_specifics)

        prompt_to_image(prompt)

        reward += get_human_feedback()

        self.state = reward

        return self.state, reward, True, {}

    def render(self, mode="human"):
        if mode == "human":
          # Display the current image
          self.image.show()
        elif mode == "rgb_array":
          # Return an RGB array of the current image
          return self.image.convert("RGB")

persuasion_strategies = ["Liking", "Social Proof", "Scarcity", "Authority", "Consistency", "Reciprocity", "Contrast", "Unity", "Consensus", "Emotion", "Scarcity", "Urgency", "Exclusivity", "Curiosity", "Anticipation", "Mystery", "Surprise", "Humor"]
env = AdsEnv(persuasion_strategies)
#rgb_array = env.render(mode="rgb_array")

!pip install shimmy>=0.2.1

agent = stable_baselines3.PPO('MlpPolicy', env)
agent.learn(total_timesteps=10000)

"""Test function (Ignore)"""